{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO en Tiempo Real: Detección de Objetos\n",
    "\n",
    "Bienvenidos a este cuaderno de Jupyter, donde exploraremos la emocionante tarea de la detección de objetos en tiempo real utilizando YOLO (You Only Look Once), una técnica avanzada de visión por computadora.\n",
    "\n",
    "En este cuaderno, aprenderás a utilizar YOLO para identificar y localizar diversos objetos en imágenes y secuencias de video. Esta habilidad es esencial en una amplia gama de aplicaciones, desde la conducción autónoma hasta la vigilancia de seguridad, y representa uno de los avances más emocionantes en el campo de la inteligencia artificial y la visión por computadora.\n",
    "\n",
    "A lo largo de este curso, explorarás conceptos clave como:\n",
    "\n",
    "- Detección de objetos en tiempo real.\n",
    "- Configuración de modelos YOLO pre-entrenados.\n",
    "- Interpretación de resultados de detección.\n",
    "- Aplicaciones prácticas de la detección de objetos.\n",
    "\n",
    "¡Prepárate para sumergirte en un emocionante mundo de visión por computadora y adquirir habilidades valiosas que te servirán en tu carrera en inteligencia artificial y más allá!\n",
    "\n",
    "Recuerda consultar este cuaderno para acceder a los recursos y ejemplos que te ayudarán a comprender YOLO y la percepción computacional en tiempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código utiliza el comando `!pip` para instalar dos paquetes de Python: `opencv-python` y `ultralytics`.\n",
    "\n",
    "- `opencv-python`: Esta es una biblioteca popular para tareas de visión por computadora en Python. Proporciona una variedad de funciones para el procesamiento de imágenes y videos, incluyendo detección de objetos, manipulación de imágenes y extracción de características.\n",
    "\n",
    "- `ultralytics`: Esta es una biblioteca construida sobre PyTorch, que se enfoca principalmente en tareas de visión por computadora como detección de objetos y clasificación de imágenes. Proporciona interfaces fáciles de usar para entrenar y evaluar modelos de aprendizaje profundo para estas tareas.\n",
    "\n",
    "Al ejecutar este comando, estás instalando estos paquetes en tu entorno de Python para que puedas usarlos en tu código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.21.2 (from opencv-python)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.26.4 opencv-python-4.9.0.80\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.2.11-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m208.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib>=3.3.0 (from ultralytics)\n",
      "  Using cached matplotlib-3.8.4-cp311-cp311-macosx_10_12_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (4.9.0.80)\n",
      "Collecting pillow>=7.1.2 (from ultralytics)\n",
      "  Using cached pillow-10.3.0-cp311-cp311-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Using cached scipy-1.13.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m470.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting psutil (from ultralytics)\n",
      "  Using cached psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl.metadata (21 kB)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Using cached pandas-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached contourpy-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached fonttools-4.51.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (159 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Collecting packaging>=20.0 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.8.0->ultralytics)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.8.0->ultralytics)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.8.0->ultralytics)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading ultralytics-8.2.11-py3-none-any.whl (756 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.5/756.5 kB\u001b[0m \u001b[31m452.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.8.4-cp311-cp311-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "Using cached pandas-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "Using cached pillow-10.3.0-cp311-cp311-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl (187 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached scipy-1.13.0-cp311-cp311-macosx_10_9_x86_64.whl (39.3 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m229.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:14\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m247.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m171.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached psutil-5.9.8-cp36-abi3-macosx_10_9_x86_64.whl (248 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl (121 kB)\n",
      "Using cached contourpy-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl (262 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.51.0-cp311-cp311-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-macosx_10_9_x86_64.whl (68 kB)\n",
      "Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m165.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m140.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl (14 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, mpmath, urllib3, tzdata, typing-extensions, tqdm, sympy, six, scipy, pyyaml, pyparsing, psutil, pillow, packaging, networkx, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, cycler, contourpy, charset-normalizer, certifi, requests, python-dateutil, jinja2, torch, pandas, matplotlib, torchvision, thop, seaborn, ultralytics\n",
      "Successfully installed MarkupSafe-2.1.5 certifi-2024.2.2 charset-normalizer-3.3.2 contourpy-1.2.1 cycler-0.12.1 filelock-3.14.0 fonttools-4.51.0 fsspec-2024.3.1 idna-3.7 jinja2-3.1.4 kiwisolver-1.4.5 matplotlib-3.8.4 mpmath-1.3.0 networkx-3.3 packaging-24.0 pandas-2.2.2 pillow-10.3.0 psutil-5.9.8 py-cpuinfo-9.0.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.1 requests-2.31.0 scipy-1.13.0 seaborn-0.13.2 six-1.16.0 sympy-1.12 thop-0.1.1.post2209072238 torch-2.2.2 torchvision-0.17.2 tqdm-4.66.4 typing-extensions-4.11.0 tzdata-2024.1 ultralytics-8.2.11 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# Instalamos los paquetes necesarios\n",
    "!pip install opencv-python\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código importa tres bibliotecas en Python:\n",
    "\n",
    "1. `ultralytics`: Esta es una biblioteca que proporciona una interfaz para usar modelos de detección de objetos YOLO (You Only Look Once). Permite entrenar, evaluar y utilizar modelos de detección de objetos de manera eficiente.\n",
    "\n",
    "2. `cv2` (OpenCV): Esta es una biblioteca popular para el procesamiento de imágenes y videos en Python. Proporciona una amplia gama de funciones para trabajar con imágenes y videos, incluyendo cargar imágenes, realizar operaciones de procesamiento de imágenes, y mostrar imágenes en una ventana, entre otros.\n",
    "\n",
    "3. `math`: Este es un módulo estándar de Python que proporciona funciones matemáticas comunes, como funciones trigonométricas, logarítmicas y aritméticas.\n",
    "\n",
    "El código importa estas bibliotecas para utilizarlas en el resto del programa, pero en este fragmento específico no se están utilizando ninguna función o clase de estas bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo YOLO pre-entrenado\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista de nombres de clases para identificar objetos detectados\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ] # Aquí se enumeran todas las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:51:38.104 Python[43566:21680708] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 tie, 184.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.27\n",
      "Class name --> tie\n",
      "Speed: 6.0ms preprocess, 184.8ms inference, 3217.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:51:54.745 Python[43566:21680708] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tie, 2141.5ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.77\n",
      "Class name --> tie\n",
      "Speed: 4.0ms preprocess, 2141.5ms inference, 44.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 420.7ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.65\n",
      "Class name --> tie\n",
      "Confidence ---> 0.27\n",
      "Class name --> tie\n",
      "Speed: 30.1ms preprocess, 420.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 210.6ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.58\n",
      "Class name --> tie\n",
      "Confidence ---> 0.31\n",
      "Class name --> tie\n",
      "Speed: 12.3ms preprocess, 210.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 152.3ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.69\n",
      "Class name --> tie\n",
      "Speed: 2.1ms preprocess, 152.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 151.2ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.66\n",
      "Class name --> tie\n",
      "Speed: 2.8ms preprocess, 151.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 141.6ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.68\n",
      "Class name --> tie\n",
      "Confidence ---> 0.28\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 141.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 136.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 136.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 126.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> tie\n",
      "Confidence ---> 0.26\n",
      "Class name --> tie\n",
      "Speed: 2.1ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 127.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.63\n",
      "Class name --> tie\n",
      "Speed: 2.1ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 191.4ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.52\n",
      "Class name --> tie\n",
      "Speed: 2.1ms preprocess, 191.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 132.8ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.7\n",
      "Class name --> tie\n",
      "Speed: 3.4ms preprocess, 132.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 132.8ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.39\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 132.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 139.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.49\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 139.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 248.2ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.56\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 248.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 192.7ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 4.2ms preprocess, 192.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 140.6ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.46\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 140.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 379.2ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 2.3ms preprocess, 379.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.3ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 2.2ms preprocess, 132.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 127.5ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Confidence ---> 0.3\n",
      "Class name --> tie\n",
      "Speed: 2.5ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.9ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 2.0ms preprocess, 135.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.1ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 3.1ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.0ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Speed: 2.1ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 128.2ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.35\n",
      "Class name --> tie\n",
      "Speed: 2.9ms preprocess, 128.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 142.1ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Speed: 18.2ms preprocess, 142.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 124.0ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Confidence ---> 0.29\n",
      "Class name --> tie\n",
      "Speed: 2.3ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 127.3ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Speed: 2.6ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 122.8ms\n",
      "Confidence ---> 0.9\n",
      "Class name --> person\n",
      "Speed: 2.2ms preprocess, 122.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.1ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Speed: 2.1ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.5ms\n",
      "Confidence ---> 0.89\n",
      "Class name --> person\n",
      "Speed: 2.6ms preprocess, 133.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Configuramos la captura de video desde la cámara\n",
    "cap = cv2.VideoCapture(0) # Se abre la cámara por defecto\n",
    "cap.set(3, 640) # Ancho de la imagen\n",
    "cap.set(4, 480) # Alto de la imagen\n",
    "\n",
    "# Iniciamos un bucle para procesar los fotogramas de la cámara\n",
    "while True:\n",
    "    success, img = cap.read() # Capturamos un fotograma\n",
    "\n",
    "    # Realizamos la detección de objetos en la imagen capturada (usando el modelo de YOLO pre-entrenado que cargamos anteriormente)\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "   # Procesamos los resultados de la detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Iteramos sobre las cajas delimitadoras detectadas\n",
    "        for box in boxes:\n",
    "            # Obtenemos las coordenadas de la caja delimitadora\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # Convertimos a valores enteros\n",
    "\n",
    "            # Dibujamos la caja delimitadora en la imagen\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)\n",
    "\n",
    "            # Obtenemos la confianza de la detección\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # Obtenemos el nombre de la clase detectada\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # Mostramos el nombre de la clase junto a la caja delimitadora\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0) # Color: Azul (formato BGR)\n",
    "            thickness = 1\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    # Mostramos la imagen con las detecciones\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # Salimos del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
